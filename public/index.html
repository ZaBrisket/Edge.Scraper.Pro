<!-- 
  This application is a single-file, production-grade AI Web Scraper.
  It uses a brutalist, early-web UI and all network requests
  are handled by serverless Netlify Functions for security.
-->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Web Scraper</title>
    <style>
        /* Brutalist, Early-Web UI Theme */
        body { 
            font-family: serif; 
            background-color: #fff; 
            color: #000;
            margin: 0;
            padding: 1em;
            display: flex;
            justify-content: center;
        }
        .container {
            width: 100%;
            max-width: 900px;
            border: 1px solid #000;
            padding: 1em;
        }
        h1 { font-size: 2em; margin-bottom: 0.5em; font-weight: bold; }
        p { margin-bottom: 1em; }
        a { color: #0000ff; }
        a:visited { color: #800080; }

        .section {
            border: 1px solid #000;
            padding: 1em;
            margin-bottom: 1em;
        }

        input[type="url"], input[type="number"], textarea {
            width: 100%;
            padding: 0.5em;
            font-family: monospace;
            border: 1px solid #000;
            margin-bottom: 1em;
            box-sizing: border-box;
        }
        textarea {
             min-height: 150px;
        }

        button {
            padding: 0.5em 1em;
            border: 1px solid #000;
            background-color: #eee;
            cursor: pointer;
            font-weight: bold;
        }
        button:hover { background-color: #ddd; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }

        #resultsCode {
            background-color: #f5f5f5;
            border: 1px solid #000;
            padding: 1em;
            height: 400px;
            overflow: auto;
            font-family: monospace;
            white-space: pre-wrap;
            word-break: break-word;
        }
        
        .spinner {
            border: 4px solid #ccc;
            border-radius: 50%;
            border-top: 4px solid #000;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 2em auto;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        .hidden { display: none; }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Web Scraper</h1>
        <p>A tool to scrape websites in bulk. Built for function over form.</p>

        <div id="bulkInputs" class="section">
            <p><b>Instructions:</b> Paste a list of URLs (one per line) to scrape all text from each page.</p>
            <textarea id="urlList" placeholder="https://example.com/page1&#10;https://example.com/page2"></textarea>
        </div>
        
        <div class="section">
            <p><b>Step 2:</b> Configure scrape settings and run.</p>
            <div style="display: flex; align-items: center; gap: 1em; margin-bottom: 1em;">
                <label for="concurrency">Concurrency:</label>
                <input id="concurrency" type="range" min="1" max="10" value="5" style="flex-grow: 1;" />
                <span id="concurrencyValue">5</span>
                <label for="delay" style="margin-left: 2em;">Delay (ms):</label>
                <input id="delay" type="number" value="250" style="width: 80px; margin-bottom: 0;"/>
            </div>
             <div style="display: flex; gap: 1em;">
                <button id="scrapeBtn" style="width: 100%;">Scrape</button>
                <button id="pauseBtn" class="hidden">Pause</button>
                <button id="resumeBtn" class="hidden">Resume</button>
                <button id="stopBtn" class="hidden">Stop</button>
            </div>
        </div>

        <div class="section">
             <p><b>Step 3:</b> Review and export results.</p>
            <div id="statusContainer" class="hidden">
                <div class="spinner"></div>
                <p id="statusText" style="text-align: center;"></p>
            </div>
            <div id="errorBox" class="hidden" style="color: red; border: 1px solid red; padding: 1em; margin-bottom: 1em;">
                <b>Error:</b> <span id="errorMessage"></span>
            </div>
            <div id="resultsContainer" style="display:none;">
                 <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1em;">
                    <div>
                        <label><input type="checkbox" id="includeHtmlToggle"> Include Raw HTML</label>
                    </div>
                    <div>
                        <button id="copyBtn">Copy</button>
                        <button id="downloadTxtBtn">Download .txt</button>
                        <button id="downloadJsonlBtn">Download .jsonl</button>
                        <button id="downloadCsvBtn">Download .csv</button>
                    </div>
                </div>
                <div id="resultsCode"></div>
            </div>
        </div>
    </div>

    <script>
        const dom = {
            bulkInputs: document.getElementById('bulkInputs'),
            urlList: document.getElementById('urlList'),
            scrapeBtn: document.getElementById('scrapeBtn'),
            statusContainer: document.getElementById('statusContainer'),
            statusText: document.getElementById('statusText'),
            errorBox: document.getElementById('errorBox'),
            errorMessage: document.getElementById('errorMessage'),
            resultsContainer: document.getElementById('resultsContainer'),
            resultsCode: document.getElementById('resultsCode'),
            copyBtn: document.getElementById('copyBtn'),
            downloadTxtBtn: document.getElementById('downloadTxtBtn'),
            downloadJsonlBtn: document.getElementById('downloadJsonlBtn'),
            downloadCsvBtn: document.getElementById('downloadCsvBtn'),
            concurrencySlider: document.getElementById('concurrency'),
            concurrencyValue: document.getElementById('concurrencyValue'),
            delayInput: document.getElementById('delay'),
            pauseBtn: document.getElementById('pauseBtn'),
            resumeBtn: document.getElementById('resumeBtn'),
            stopBtn: document.getElementById('stopBtn'),
            includeHtmlToggle: document.getElementById('includeHtmlToggle'),
        };

        let state = {
            scrapeResults: [],
            runControls: { paused: false, aborted: false }
        };

        const delay = ms => new Promise(resolve => setTimeout(resolve, ms));

        const DEBUG = true;
        const log = (...args) => { if (DEBUG) console.log(new Date().toISOString(), ...args); };

        class NetworkError extends Error {
            constructor(message, status) { super(message); this.name = 'NetworkError'; this.status = status; }
        }
        class ParseError extends Error {
            constructor(message, status) { super(message); this.name = 'ParseError'; this.status = status; }
        }
        class ValidationError extends Error {
            constructor(message) { super(message); this.name = 'ValidationError'; }
        }

        const api = {
            async fetchUrl(url) {
                const response = await fetch(`/api/fetch-url?url=${encodeURIComponent(url)}`);
                const responseText = await response.text();
                const correlationId = response.headers.get('x-correlation-id');
                log(correlationId ? `[${correlationId}]` : '', `[fetchUrl] [${response.status}] ${url}:`, responseText.substring(0, 200));
                if (!response.ok) {
                    let error;
                    try {
                        const parsed = JSON.parse(responseText);
                        error = parsed.error || parsed;
                    } catch {
                        error = { message: responseText, status: response.status };
                    }
                    const errorMessage = typeof error === 'object'
                        ? (error.message || error.code || JSON.stringify(error))
                        : String(error);
                    throw new NetworkError(`[${response.status}] ${errorMessage}`, response.status);
                }
                try {
                    const parsed = JSON.parse(responseText);
                    return parsed.data?.html || parsed.html || '';
                } catch {
                    throw new ParseError('Failed to parse fetch-url response', response.status);
                }
            }
        };

        const validate = {
            url: (str) => {
                try {
                    const url = new URL(str);
                    if (!['http:', 'https:'].includes(url.protocol)) throw new ValidationError('Invalid protocol.');
                    return url.href;
                } catch {
                    throw new ValidationError(`Invalid URL: ${str}`);
                }
            }
        };

        const showError = message => { dom.errorMessage.textContent = message; dom.errorBox.classList.remove('hidden'); };

        async function verifyBackend() {
            try {
                const res = await fetch('/api/fetch-url?url=https://example.com');
                const text = await res.text();
                const correlationId = res.headers.get('x-correlation-id');
                log(correlationId ? `[${correlationId}]` : '', `[verifyBackend] [${res.status}]`, text.substring(0, 200));
                if (!res.ok) throw new Error(`Backend returned ${res.status}`);
                return true;
            } catch (e) {
                showError(`Backend verification failed: ${e.message}. Check Netlify deployment.`);
                return false;
            }
        }

        const updateRunButtons = (isScraping) => {
            dom.scrapeBtn.classList.toggle('hidden', isScraping);
            dom.pauseBtn.classList.toggle('hidden', !isScraping);
            dom.stopBtn.classList.toggle('hidden', !isScraping);
            dom.resumeBtn.classList.add('hidden');
        };

        dom.scrapeBtn.addEventListener('click', async () => {
            dom.errorBox.classList.add('hidden');
            dom.resultsContainer.style.display = 'none';
            dom.statusContainer.classList.remove('hidden');
            updateRunButtons(true);
            
            state.runControls = { paused: false, aborted: false };
            state.scrapeResults = [];
            dom.resultsCode.textContent = '';

            try {
                await runBulkScrape();
            } catch (error) {
                if (!state.runControls.aborted) {
                    console.error('Scraping Error:', error);
                    showError(error.message);
                }
            } finally {
                dom.statusContainer.classList.add('hidden');
                updateRunButtons(false);
            }
        });
        
        dom.concurrencySlider.addEventListener('input', () => dom.concurrencyValue.textContent = dom.concurrencySlider.value);
        dom.pauseBtn.addEventListener('click', () => {
            state.runControls.paused = true;
            dom.pauseBtn.classList.add('hidden');
            dom.resumeBtn.classList.remove('hidden');
            dom.statusText.textContent = 'Scraping paused...';
        });
        dom.resumeBtn.addEventListener('click', () => {
            state.runControls.paused = false;
            dom.resumeBtn.classList.add('hidden');
            dom.pauseBtn.classList.remove('hidden');
        });
        dom.stopBtn.addEventListener('click', () => {
            state.runControls.aborted = true;
            dom.statusText.textContent = 'Scraping stopped by user.';
        });

        const cooperativelyYield = async () => {
            while (state.runControls.paused) await delay(200);
            if (state.runControls.aborted) throw new Error('Run aborted by user');
        };

        const cleanUrl = (href) => {
            try {
                const url = new URL(href);
                url.hash = '';
                ['utm_source', 'utm_medium', 'utm_campaign', 'utm_term', 'utm_content', 'gclid', 'fbclid'].forEach(p => url.searchParams.delete(p));
                return url.href;
            } catch { return href; }
        };

        async function runBulkScrape() {
            if (!await verifyBackend()) return;
            const urls = dom.urlList.value.trim().split('\n').filter(Boolean).map(url => cleanUrl(validate.url(url)));
            if (urls.length === 0) throw new Error('Please paste at least one valid URL.');
            await processUrlsInParallel(urls, 'Scraping URL');
        }

        async function processUrlsInParallel(urls, statusPrefix) {
            let completed = 0;
            const maxConcurrency = parseInt(dom.concurrencySlider.value, 10);
            const perRequestDelay = parseInt(dom.delayInput.value, 10);
            const urlQueue = [...new Set(urls)].map((url, index) => ({ index, url }));
            const totalUrls = urlQueue.length;
            state.scrapeResults = new Array(totalUrls);

            const renderResults = () => {
                dom.resultsCode.textContent = state.scrapeResults
                    .filter(Boolean).sort((a, b) => a.index - b.index)
                    .map(r => {
                        let output = `\n\n--- Content from ${r.url} ---\n\n`;
                        if(r.error) output += `Error: ${r.error}`;
                        else {
                            if(r.metadata.title) output += `Title: ${r.metadata.title}\n`;
                            if(r.metadata.author) output += `Author: ${r.metadata.author}\n`;
                            if(r.metadata.published_at) output += `Published: ${r.metadata.published_at}\n`;
                            if(r.metadata.description) output += `Description: ${r.metadata.description}\n\n`;
                            output += r.text;
                        }
                        return output;
                    }).join('');
            };

            async function worker() {
                while (urlQueue.length > 0 && !state.runControls.aborted) {
                    await cooperativelyYield();
                    if (state.runControls.aborted) break;
                    
                    const { index, url } = urlQueue.shift();
                    try {
                        dom.statusText.textContent = `${statusPrefix} (${completed + 1}/${totalUrls}): ${url.substring(0, 50)}...`;
                        const html = await api.fetchUrl(url);
                        const doc = new DOMParser().parseFromString(html, 'text/html');
                        const metadata = extractMetadata(doc);
                        const text = extractMainContent(doc);
                        state.scrapeResults[index] = { index, url, text, metadata, html: dom.includeHtmlToggle.checked ? html : null, success: true };
                    } catch (error) {
                        console.error(`Failed to scrape ${url}:`, error);
                        const errorDetails = {
                            message: error.message || error.toString(),
                            status: error.status,
                            stack: error.stack
                        };
                        state.scrapeResults[index] = {
                            index,
                            url,
                            text: '',
                            metadata: {},
                            success: false,
                            error: errorDetails.message,
                            errorDetails,
                            html: null
                        };
                    } finally {
                        completed++;
                        renderResults();
                    }
                    await delay(perRequestDelay);
                }
            }
            
            const workers = Array(Math.min(maxConcurrency, totalUrls)).fill(null).map(worker);
            dom.resultsContainer.style.display = 'block';
            await Promise.all(workers);

            if (!state.runControls.aborted) dom.statusText.textContent = `Scrape complete! Processed ${completed} URLs.`;
        }

        function extractMetadata(doc) {
            const get = (selector, attr = 'content') => doc.querySelector(selector)?.getAttribute(attr) || '';
            return {
                title: get('meta[property="og:title"]') || doc.title || '',
                description: get('meta[name="description"]') || get('meta[property="og:description"]') || '',
                author: get('meta[name="author"]') || '',
                published_at: get('meta[property="article:published_time"]') || get('meta[name="date"]') || ''
            };
        }

        function extractMainContent(doc) {
             const docClone = doc.cloneNode(true);
             docClone.querySelectorAll('script, style, nav, footer, header, aside, form, [role="navigation"], [role="banner"], [role="complementary"], noscript, iframe, svg').forEach(el => el.remove());
             const candidates = Array.from(docClone.querySelectorAll('main, article, [role="main"], .main-content, .post, .post-body, .entry, .entry-content, #content, .content, section'));
             if (docClone.body) candidates.push(docClone.body);

             const scoreNode = (node) => {
                if (!node || !node.innerText) return 0;
                const text = node.innerText.trim();
                const textLength = text.length;
                if (textLength < 100) return 0;
                const linkCount = node.querySelectorAll('a').length;
                const pCount = node.querySelectorAll('p').length;
                const headingCount = node.querySelectorAll('h1, h2, h3').length;
                const linkDensity = linkCount / (text.split(/\s+/).length + 1);
                return (textLength * (1 - linkDensity)) + (pCount * 50) + (headingCount * 100);
             };

             let bestNode = docClone.body, maxScore = 0;
             candidates.forEach(node => {
                const score = scoreNode(node);
                if (score > maxScore) { maxScore = score; bestNode = node; }
             });

             let mainText = bestNode?.innerText?.trim() || '';
             if (mainText.length < 200) {
                 const metaDescription = extractMetadata(doc).description;
                 if (metaDescription && metaDescription.length > mainText.length) mainText = metaDescription;
             }
             return mainText.replace(/(\r\n|\n|\r){3,}/g, '\n\n');
        }
        
        function downloadFile(filename, text) {
            const blob = new Blob([text], { type: 'text/plain;charset=utf-8' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url; a.download = filename;
            document.body.appendChild(a); a.click();
            document.body.removeChild(a); URL.revokeObjectURL(url);
        }

        dom.downloadTxtBtn.addEventListener('click', () => {
            const textContent = state.scrapeResults.filter(Boolean).sort((a,b)=> a.index - b.index).map(r => `--- Content from ${r.url} ---\n\n${r.error ? `ERROR: ${r.error}` : r.text}`).join('\n\n');
            downloadFile('scrape_results.txt', textContent);
        });

        dom.downloadJsonlBtn.addEventListener('click', () => {
            const jsonlContent = state.scrapeResults.filter(Boolean).sort((a,b)=> a.index - b.index).map(r => JSON.stringify(r)).join('\n');
            downloadFile('scrape_results.jsonl', jsonlContent);
        });
        
        dom.downloadCsvBtn.addEventListener('click', () => {
            const header = ['url', 'title', 'author', 'published_at', 'description', 'text', 'success', 'error', 'html'];
            const esc = s => `"${(s || '').toString().replace(/"/g, '""')}"`;
            const rows = state.scrapeResults.filter(Boolean).sort((a,b)=> a.index - b.index).map(r => {
                const { url, metadata, text, success, error, html } = r;
                return [url, metadata.title, metadata.author, metadata.published_at, metadata.description, text, success, error, dom.includeHtmlToggle.checked ? html : ''].map(esc).join(',');
            });
            downloadFile('scrape_results.csv', [header.join(','), ...rows].join('\n'));
        });

        dom.copyBtn.addEventListener('click', async () => {
            try {
                await navigator.clipboard.writeText(dom.resultsCode.textContent);
                dom.copyBtn.textContent = 'Copied!';
                setTimeout(() => { dom.copyBtn.textContent = 'Copy'; }, 2000);
            } catch (err) { showError('Failed to copy text.'); }
        });
    </script>
</body>
</html>
