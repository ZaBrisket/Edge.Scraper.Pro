<!-- 
  This application is a single-file, production-grade AI Web Scraper.
  It uses a brutalist, early-web UI and all network requests
  are handled by serverless Netlify Functions for security.
-->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Web Scraper</title>
    <style>
        /* Brutalist, Early-Web UI Theme */
        body { 
            font-family: serif; 
            background-color: #fff; 
            color: #000;
            margin: 0;
            padding: 1em;
            display: flex;
            justify-content: center;
        }
        .container {
            width: 100%;
            max-width: 900px;
            border: 1px solid #000;
            padding: 1em;
        }
        h1 { font-size: 2em; margin-bottom: 0.5em; font-weight: bold; }
        p { margin-bottom: 1em; }
        a { color: #0000ff; }
        a:visited { color: #800080; }

        .section {
            border: 1px solid #000;
            padding: 1em;
            margin-bottom: 1em;
        }

        input[type="url"], input[type="number"], textarea {
            width: 100%;
            padding: 0.5em;
            font-family: monospace;
            border: 1px solid #000;
            margin-bottom: 1em;
            box-sizing: border-box;
        }
        textarea {
             min-height: 150px;
        }

        button {
            padding: 0.5em 1em;
            border: 1px solid #000;
            background-color: #eee;
            cursor: pointer;
            font-weight: bold;
        }
        button:hover { background-color: #ddd; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }

        #resultsCode {
            background-color: #f5f5f5;
            border: 1px solid #000;
            padding: 1em;
            height: 400px;
            overflow: auto;
            font-family: monospace;
            white-space: pre-wrap;
            word-break: break-word;
        }
        
        .spinner {
            border: 4px solid #ccc;
            border-radius: 50%;
            border-top: 4px solid #000;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 2em auto;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        .hidden { display: none; }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Web Scraper</h1>
        <p>A tool to scrape websites in bulk. Built for function over form.</p>

        <div id="bulkInputs" class="section">
            <p><b>Instructions:</b> Paste a list of URLs (one per line) to scrape all text from each page.</p>
            <textarea id="urlList" placeholder="https://example.com/page1&#10;https://example.com/page2"></textarea>
        </div>
        
        <div class="section">
            <p><b>Step 2:</b> Configure scrape settings and run.</p>
            <div style="display: flex; align-items: center; gap: 1em; margin-bottom: 1em;">
                <label for="concurrency">Concurrency:</label>
                <input id="concurrency" type="range" min="1" max="10" value="5" style="flex-grow: 1;" />
                <span id="concurrencyValue">5</span>
                <label for="delay" style="margin-left: 2em;">Delay (ms):</label>
                <input id="delay" type="number" value="250" style="width: 80px; margin-bottom: 0;"/>
            </div>
             <div style="display: flex; gap: 1em;">
                <button id="scrapeBtn" style="width: 100%;">Scrape</button>
                <button id="pauseBtn" class="hidden">Pause</button>
                <button id="resumeBtn" class="hidden">Resume</button>
                <button id="stopBtn" class="hidden">Stop</button>
            </div>
        </div>

        <div class="section">
             <p><b>Step 3:</b> Review and export results.</p>
            <div id="statusContainer" class="hidden">
                <div class="spinner"></div>
                <p id="statusText" style="text-align: center;"></p>
            </div>
            <div id="errorBox" class="hidden" style="color: red; border: 1px solid red; padding: 1em; margin-bottom: 1em;">
                <b>Error:</b> <span id="errorMessage"></span>
            </div>
            <div id="resultsContainer" style="display:none;">
                 <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1em;">
                    <div>
                        <label><input type="checkbox" id="includeHtmlToggle"> Include Raw HTML</label>
                    </div>
                    <div>
                        <button id="copyBtn">Copy</button>
                        <button id="downloadTxtBtn">Download .txt</button>
                        <button id="downloadJsonlBtn">Download .jsonl</button>
                        <button id="downloadCsvBtn">Download .csv</button>
                    </div>
                </div>
                <div id="resultsCode"></div>
            </div>
        </div>
    </div>

    <script>
        const dom = {
            bulkInputs: document.getElementById('bulkInputs'),
            urlList: document.getElementById('urlList'),
            scrapeBtn: document.getElementById('scrapeBtn'),
            statusContainer: document.getElementById('statusContainer'),
            statusText: document.getElementById('statusText'),
            errorBox: document.getElementById('errorBox'),
            errorMessage: document.getElementById('errorMessage'),
            resultsContainer: document.getElementById('resultsContainer'),
            resultsCode: document.getElementById('resultsCode'),
            copyBtn: document.getElementById('copyBtn'),
            downloadTxtBtn: document.getElementById('downloadTxtBtn'),
            downloadJsonlBtn: document.getElementById('downloadJsonlBtn'),
            downloadCsvBtn: document.getElementById('downloadCsvBtn'),
            concurrencySlider: document.getElementById('concurrency'),
            concurrencyValue: document.getElementById('concurrencyValue'),
            delayInput: document.getElementById('delay'),
            pauseBtn: document.getElementById('pauseBtn'),
            resumeBtn: document.getElementById('resumeBtn'),
            stopBtn: document.getElementById('stopBtn'),
            includeHtmlToggle: document.getElementById('includeHtmlToggle'),
        };

        let state = {
            scrapeResults: [],
            runControls: { paused: false, aborted: false }
        };

        const delay = ms => new Promise(resolve => setTimeout(resolve, ms));

        const DEBUG = true;
        const log = (...args) => { if (DEBUG) console.log(new Date().toISOString(), ...args); };

        class NetworkError extends Error {
            constructor(message, status) { super(message); this.name = 'NetworkError'; this.status = status; }
        }
        class ParseError extends Error {
            constructor(message, status) { super(message); this.name = 'ParseError'; this.status = status; }
        }
        class ValidationError extends Error {
            constructor(message) { super(message); this.name = 'ValidationError'; }
        }

        const api = {
            async fetchUrl(url) {
                const response = await fetch(`/api/fetch-url?url=${encodeURIComponent(url)}`);
                const responseText = await response.text();
                const correlationId = response.headers.get('x-correlation-id');
                log(correlationId ? `[${correlationId}]` : '', `[fetchUrl] [${response.status}] ${url}:`, responseText.substring(0, 200));
                if (!response.ok) {
                    let error;
                    try {
                        const parsed = JSON.parse(responseText);
                        error = parsed.error || parsed;
                    } catch {
                        error = { message: responseText, status: response.status };
                    }
                    const errorMessage = typeof error === 'object'
                        ? (error.message || error.code || JSON.stringify(error))
                        : String(error);
                    throw new NetworkError(`[${response.status}] ${errorMessage}`, response.status);
                }
                try {
                    const parsed = JSON.parse(responseText);
                    return parsed.data?.html || parsed.html || '';
                } catch {
                    throw new ParseError('Failed to parse fetch-url response', response.status);
                }
            }
        };

        const validate = {
            url: (str) => {
                try {
                    const url = new URL(str);
                    if (!['http:', 'https:'].includes(url.protocol)) throw new ValidationError('Invalid protocol.');
                    return url.href;
                } catch {
                    throw new ValidationError(`Invalid URL: ${str}`);
                }
            }
        };

        const showError = message => { dom.errorMessage.textContent = message; dom.errorBox.classList.remove('hidden'); };

        async function verifyBackend() {
            try {
                const res = await fetch('/api/fetch-url?url=https://example.com');
                const text = await res.text();
                const correlationId = res.headers.get('x-correlation-id');
                log(correlationId ? `[${correlationId}]` : '', `[verifyBackend] [${res.status}]`, text.substring(0, 200));
                if (!res.ok) throw new Error(`Backend returned ${res.status}`);
                return true;
            } catch (e) {
                showError(`Backend verification failed: ${e.message}. Check Netlify deployment.`);
                return false;
            }
        }

        const updateRunButtons = (isScraping) => {
            dom.scrapeBtn.classList.toggle('hidden', isScraping);
            dom.pauseBtn.classList.toggle('hidden', !isScraping);
            dom.stopBtn.classList.toggle('hidden', !isScraping);
            dom.resumeBtn.classList.add('hidden');
        };

        dom.scrapeBtn.addEventListener('click', async () => {
            dom.errorBox.classList.add('hidden');
            dom.resultsContainer.style.display = 'none';
            dom.statusContainer.classList.remove('hidden');
            updateRunButtons(true);
            
            state.runControls = { paused: false, aborted: false };
            state.scrapeResults = [];
            dom.resultsCode.textContent = '';

            try {
                await runBulkScrape();
            } catch (error) {
                if (!state.runControls.aborted) {
                    console.error('Scraping Error:', error);
                    showError(error.message);
                }
            } finally {
                dom.statusContainer.classList.add('hidden');
                updateRunButtons(false);
            }
        });
        
        dom.concurrencySlider.addEventListener('input', () => dom.concurrencyValue.textContent = dom.concurrencySlider.value);
        dom.pauseBtn.addEventListener('click', () => {
            state.runControls.paused = true;
            dom.pauseBtn.classList.add('hidden');
            dom.resumeBtn.classList.remove('hidden');
            dom.statusText.textContent = 'Scraping paused...';
        });
        dom.resumeBtn.addEventListener('click', () => {
            state.runControls.paused = false;
            dom.resumeBtn.classList.add('hidden');
            dom.pauseBtn.classList.remove('hidden');
        });
        dom.stopBtn.addEventListener('click', () => {
            state.runControls.aborted = true;
            dom.statusText.textContent = 'Scraping stopped by user.';
        });

        const cooperativelyYield = async () => {
            while (state.runControls.paused) await delay(200);
            if (state.runControls.aborted) throw new Error('Run aborted by user');
        };

        const cleanUrl = (href) => {
            try {
                const url = new URL(href);
                url.hash = '';
                ['utm_source', 'utm_medium', 'utm_campaign', 'utm_term', 'utm_content', 'gclid', 'fbclid'].forEach(p => url.searchParams.delete(p));
                return url.href;
            } catch { return href; }
        };

        async function runBulkScrape() {
            if (!await verifyBackend()) return;
            const urls = dom.urlList.value.trim().split('\n').filter(Boolean).map(url => cleanUrl(validate.url(url)));
            if (urls.length === 0) throw new Error('Please paste at least one valid URL.');
            await processUrlsInParallel(urls, 'Scraping URL');
        }

        async function processUrlsInParallel(urls, statusPrefix) {
            let completed = 0;
            const maxConcurrency = parseInt(dom.concurrencySlider.value, 10);
            const perRequestDelay = parseInt(dom.delayInput.value, 10);
            const urlQueue = [...new Set(urls)].map((url, index) => ({ index, url }));
            const totalUrls = urlQueue.length;
            state.scrapeResults = new Array(totalUrls);

            const renderResults = () => {
                dom.resultsCode.textContent = state.scrapeResults
                    .filter(Boolean).sort((a, b) => a.index - b.index)
                    .map(r => {
                        let output = `\n\n--- Content from ${r.url} ---\n\n`;
                        if(r.error) output += `Error: ${r.error}`;
                        else {
                            if(r.metadata.title) output += `Title: ${r.metadata.title}\n`;
                            if(r.metadata.author) output += `Author: ${r.metadata.author}\n`;
                            if(r.metadata.published_at) output += `Published: ${r.metadata.published_at}\n`;
                            if(r.metadata.description) output += `Description: ${r.metadata.description}\n\n`;
                            output += r.text;
                        }
                        return output;
                    }).join('');
            };

            async function worker() {
                while (urlQueue.length > 0 && !state.runControls.aborted) {
                    await cooperativelyYield();
                    if (state.runControls.aborted) break;
                    
                    const { index, url } = urlQueue.shift();
                    try {
                        dom.statusText.textContent = `${statusPrefix} (${completed + 1}/${totalUrls}): ${url.substring(0, 50)}...`;
                        const html = await api.fetchUrl(url);
                        const doc = new DOMParser().parseFromString(html, 'text/html');
                        const metadata = extractMetadata(doc);
                        const extractionResult = extractMainContentWithDebug(doc);
                        const text = extractionResult.content;
                        
                        // Log extraction details for debugging
                        if (DEBUG) {
                            console.log(`[Content Extraction] ${url}:`, {
                                selectedMethod: extractionResult.method,
                                contentLength: text.length,
                                score: extractionResult.score,
                                candidatesFound: extractionResult.candidatesCount
                            });
                        }
                        
                        state.scrapeResults[index] = { 
                            index, url, text, metadata, 
                            html: dom.includeHtmlToggle.checked ? html : null, 
                            success: true,
                            extractionDebug: extractionResult.debug
                        };
                    } catch (error) {
                        console.error(`Failed to scrape ${url}:`, error);
                        const errorDetails = {
                            message: error.message || error.toString(),
                            status: error.status,
                            stack: error.stack
                        };
                        state.scrapeResults[index] = {
                            index,
                            url,
                            text: '',
                            metadata: {},
                            success: false,
                            error: errorDetails.message,
                            errorDetails,
                            html: null
                        };
                    } finally {
                        completed++;
                        renderResults();
                    }
                    await delay(perRequestDelay);
                }
            }
            
            const workers = Array(Math.min(maxConcurrency, totalUrls)).fill(null).map(worker);
            dom.resultsContainer.style.display = 'block';
            await Promise.all(workers);

            if (!state.runControls.aborted) dom.statusText.textContent = `Scrape complete! Processed ${completed} URLs.`;
        }

        function extractMetadata(doc) {
            const get = (selector, attr = 'content') => doc.querySelector(selector)?.getAttribute(attr) || '';
            return {
                title: get('meta[property="og:title"]') || doc.title || '',
                description: get('meta[name="description"]') || get('meta[property="og:description"]') || '',
                author: get('meta[name="author"]') || '',
                published_at: get('meta[property="article:published_time"]') || get('meta[name="date"]') || ''
            };
        }

        function extractMainContentWithDebug(doc) {
            const result = extractMainContentInternal(doc);
            return {
                content: result.content,
                method: result.selectedContent?.source || 'fallback',
                score: result.selectedContent?.score || 0,
                candidatesCount: result.candidatesCount,
                debug: {
                    method: result.selectedContent?.source || 'fallback',
                    score: result.selectedContent?.score || 0,
                    candidates: result.candidatesCount,
                    contentLength: result.content.length
                }
            };
        }

        function extractMainContent(doc) {
            return extractMainContentInternal(doc).content;
        }

        function extractMainContentInternal(doc) {
            // Multi-pass content detection with comprehensive selector patterns
            const docClone = doc.cloneNode(true);
            
            // Phase 1: Surgical content cleaning - preserve content-bearing elements
            const removeSelectors = [
                'script', 'style', 'noscript', 'iframe', 'object', 'embed',
                'nav:not([class*="content"]):not([id*="content"])', 
                'footer:not([class*="content"]):not([id*="content"])', 
                'header:not([class*="content"]):not([id*="content"])',
                'aside:not([class*="content"]):not([id*="content"]):not([class*="article"])',
                'form:not([class*="content"]):not([id*="content"])',
                '[role="navigation"]:not([class*="content"])', 
                '[role="banner"]:not([class*="content"])', 
                '[role="complementary"]:not([class*="content"])',
                '[class*="advertisement"]', '[class*="ads"]', '[id*="ads"]',
                '[class*="sidebar"]:not([class*="content"])', '[class*="widget"]:not([class*="content"])',
                '[class*="menu"]:not([class*="content"])', '[class*="navigation"]:not([class*="content"])',
                '[class*="social"]:not([class*="content"])', '[class*="share"]:not([class*="content"])',
                '[class*="comment"]:not([class*="content"])', '[class*="footer"]:not([class*="content"])',
                '[class*="header"]:not([class*="content"])', '.skip-link', '[aria-hidden="true"]'
            ];
            
            removeSelectors.forEach(selector => {
                try {
                    docClone.querySelectorAll(selector).forEach(el => el.remove());
                } catch (e) {
                    // Continue if selector fails
                }
            });

            // Phase 2: Multi-pass content detection
            const contentResults = [];
            
            // Pass 1: Standard semantic selectors
            const semanticSelectors = [
                'main', 'article', '[role="main"]', '[role="article"]'
            ];
            contentResults.push(...findContentBySelectors(docClone, semanticSelectors, 'semantic'));
            
            // Pass 2: Comprehensive CSS class-based detection
            const classBasedSelectors = [
                // Content containers
                '[class*="content"]', '[class*="article"]', '[class*="story"]', '[class*="post"]',
                '[id*="content"]', '[id*="article"]', '[id*="story"]', '[id*="post"]',
                
                // News/blog specific
                '.post-body', '.entry-content', '.article-body', '.story-body', '.news-content',
                '.blog-post', '.blog-content', '.entry', '.post-content', '.article-content',
                '.main-content', '.primary-content', '.page-content', '.site-content',
                
                // Publication specific
                '.text', '.body', '.copy', '.editorial', '.journalism', '.reporting',
                '.publication', '.manuscript', '.document', '.paper', '.report',
                
                // Layout containers
                '.main', '.primary', '.central', '.center', '.middle',
                '[class*="main"]', '[class*="primary"]', '[class*="central"]',
                
                // Generic content indicators
                '.prose', '.rich-text', '.formatted-text', '.wysiwyg',
                '[class*="text"]', '[class*="body"]', '[class*="copy"]'
            ];
            contentResults.push(...findContentBySelectors(docClone, classBasedSelectors, 'class-based'));
            
            // Pass 3: Structured content sections
            const structuredSelectors = [
                'section[class*="content"]', 'section[id*="content"]', 'section[class*="article"]',
                'div[class*="content"]', 'div[id*="content"]', 'div[class*="article"]',
                'section:has(h1)', 'section:has(h2)', 'section:has(p)',
                '.container:has(p)', '.wrapper:has(p)', '.inner:has(p)'
            ];
            contentResults.push(...findContentBySelectors(docClone, structuredSelectors, 'structured'));
            
            // Pass 4: Largest text block analysis (fallback)
            const allTextContainers = Array.from(docClone.querySelectorAll('div, section, article, p'))
                .filter(el => el.innerText && el.innerText.trim().length > 100);
            contentResults.push(...allTextContainers.map(el => ({ element: el, source: 'text-block' })));
            
            // Add body as final fallback
            if (docClone.body) {
                contentResults.push({ element: docClone.body, source: 'body-fallback' });
            }

            // Phase 3: Advanced content scoring and selection
            const scoredResults = contentResults
                .filter(result => result.element && result.element.innerText)
                .map(result => ({
                    ...result,
                    score: advancedScoreNode(result.element),
                    text: result.element.innerText.trim()
                }))
                .filter(result => result.score > 0)
                .sort((a, b) => b.score - a.score);

            // Phase 4: Content validation and selection
            let selectedContent = null;
            const minContentThreshold = 300; // Minimum characters for substantial content
            
            for (const result of scoredResults) {
                if (result.text.length >= minContentThreshold && validateContentQuality(result.element)) {
                    selectedContent = result;
                    break;
                }
            }
            
            // If no substantial content found, try with lower threshold
            if (!selectedContent && scoredResults.length > 0) {
                selectedContent = scoredResults.find(r => r.text.length >= 100) || scoredResults[0];
            }
            
            // Phase 5: Enhanced output formatting
            let mainText = selectedContent?.text || '';
            
            // Fallback to meta description if content is still insufficient
            if (mainText.length < 200) {
                const metaDescription = extractMetadata(doc).description;
                if (metaDescription && metaDescription.length > mainText.length) {
                    mainText = metaDescription;
                }
            }
            
            // Structure and clean the extracted content
            const finalContent = structureExtractedContent(mainText, selectedContent?.element);
            
            return {
                content: finalContent,
                selectedContent,
                candidatesCount: scoredResults.length
            };
        }

        function findContentBySelectors(docClone, selectors, source) {
            const results = [];
            for (const selector of selectors) {
                try {
                    const elements = Array.from(docClone.querySelectorAll(selector));
                    results.push(...elements.map(el => ({ element: el, source })));
                } catch (e) {
                    // Continue if selector fails
                }
            }
            return results;
        }

        function advancedScoreNode(node) {
            if (!node || !node.innerText) return 0;
            
            const text = node.innerText.trim();
            const textLength = text.length;
            if (textLength < 50) return 0;
            
            // Basic metrics
            const words = text.split(/\s+/);
            const wordCount = words.length;
            const linkCount = node.querySelectorAll('a').length;
            const paragraphCount = node.querySelectorAll('p').length;
            const headingCount = node.querySelectorAll('h1, h2, h3, h4, h5, h6').length;
            const listCount = node.querySelectorAll('ul, ol').length;
            const listItemCount = node.querySelectorAll('li').length;
            
            // Quality indicators
            const sentenceCount = (text.match(/[.!?]+/g) || []).length;
            const avgWordsPerSentence = sentenceCount > 0 ? wordCount / sentenceCount : 0;
            const hasProperPunctuation = /[.!?]/.test(text);
            const hasCapitalization = /[A-Z]/.test(text);
            
            // Content structure scoring
            let structureScore = 0;
            structureScore += paragraphCount * 30; // Reward paragraph structure
            structureScore += headingCount * 80; // Reward heading hierarchy
            structureScore += listCount * 20; // Reward organized lists
            structureScore += Math.min(listItemCount * 5, 100); // Cap list item bonus
            
            // Text quality scoring
            let qualityScore = 0;
            qualityScore += textLength * 0.5; // Base text length score
            qualityScore += Math.min(wordCount * 2, 1000); // Word count bonus (capped)
            qualityScore += sentenceCount * 10; // Sentence structure bonus
            
            if (avgWordsPerSentence >= 8 && avgWordsPerSentence <= 25) {
                qualityScore += 100; // Reward good sentence length
            }
            if (hasProperPunctuation) qualityScore += 50;
            if (hasCapitalization) qualityScore += 50;
            
            // Link density penalty (but not as harsh)
            const linkDensity = linkCount / (wordCount + 1);
            const linkPenalty = linkDensity > 0.1 ? (linkDensity - 0.1) * 500 : 0;
            
            // Content-to-noise ratio
            const noiseElements = node.querySelectorAll('script, style, nav, footer, aside, .ad, .advertisement');
            const noisePenalty = noiseElements.length * 20;
            
            // Semantic relevance indicators
            let semanticBonus = 0;
            const className = node.className || '';
            const id = node.id || '';
            const semanticKeywords = ['content', 'article', 'story', 'post', 'body', 'text', 'main'];
            
            semanticKeywords.forEach(keyword => {
                if (className.toLowerCase().includes(keyword)) semanticBonus += 100;
                if (id.toLowerCase().includes(keyword)) semanticBonus += 100;
            });
            
            const finalScore = structureScore + qualityScore + semanticBonus - linkPenalty - noisePenalty;
            return Math.max(0, finalScore);
        }

        function validateContentQuality(element) {
            if (!element || !element.innerText) return false;
            
            const text = element.innerText.trim();
            const words = text.split(/\s+/);
            
            // Basic quality checks
            if (words.length < 20) return false; // Too short
            if (text.length / words.length < 3) return false; // Words too short on average
            
            // Check for reasonable sentence structure
            const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
            if (sentences.length === 0) return false;
            
            const avgWordsPerSentence = words.length / sentences.length;
            if (avgWordsPerSentence < 3 || avgWordsPerSentence > 50) return false;
            
            // Check for excessive link density
            const linkCount = element.querySelectorAll('a').length;
            const linkDensity = linkCount / words.length;
            if (linkDensity > 0.3) return false; // Too many links relative to content
            
            // Check for reasonable character distribution
            const alphaCount = (text.match(/[a-zA-Z]/g) || []).length;
            const alphaRatio = alphaCount / text.length;
            if (alphaRatio < 0.5) return false; // Too few alphabetic characters
            
            return true;
        }

        function structureExtractedContent(text, sourceElement) {
            if (!text) return '';
            
            // Clean up excessive whitespace while preserving paragraph breaks
            let cleanedText = text
                .replace(/[\r\n\t]+/g, '\n') // Normalize line breaks
                .replace(/[ \u00A0]+/g, ' ') // Normalize spaces (including non-breaking)
                .replace(/\n\s*\n\s*\n+/g, '\n\n') // Reduce multiple line breaks to double
                .trim();
            
            // If we have access to the source element, try to preserve some structure
            if (sourceElement) {
                // Try to maintain heading structure
                const headings = sourceElement.querySelectorAll('h1, h2, h3, h4, h5, h6');
                if (headings.length > 0) {
                    // Add extra spacing around headings in the text
                    headings.forEach(heading => {
                        const headingText = heading.innerText.trim();
                        if (headingText && cleanedText.includes(headingText)) {
                            cleanedText = cleanedText.replace(
                                new RegExp(`(^|\\n)(${escapeRegex(headingText)})($|\\n)`, 'g'),
                                `$1\n$2\n$3`
                            );
                        }
                    });
                }
            }
            
            // Final cleanup
            return cleanedText.replace(/\n\s*\n\s*\n+/g, '\n\n').trim();
        }

        function escapeRegex(string) {
            return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
        }

        // Test function to validate extraction improvements
        function testExtractionImprovements() {
            const testHtml = `
                <html>
                <head>
                    <title>Test Article</title>
                    <meta name="description" content="A test article for validating extraction improvements">
                </head>
                <body>
                    <nav class="navigation">Navigation content</nav>
                    <header class="site-header">Site header</header>
                    <aside class="sidebar">Sidebar content</aside>
                    
                    <main class="main-content">
                        <article class="article-body">
                            <h1>Main Article Title</h1>
                            <p>This is the first paragraph of the main article content. It contains substantial text that should be extracted by the improved algorithm.</p>
                            <p>This is the second paragraph with more detailed information. The enhanced scraper should identify this as primary content due to its structure and length.</p>
                            <h2>Subheading</h2>
                            <p>Additional content under a subheading. This demonstrates the hierarchical structure that the new scoring system should recognize and reward.</p>
                            <ul>
                                <li>List item one</li>
                                <li>List item two</li>
                            </ul>
                            <p>Final paragraph with concluding thoughts and substantial content that validates the extraction quality.</p>
                        </article>
                    </main>
                    
                    <footer class="site-footer">Footer content</footer>
                    <div class="advertisement">Ad content</div>
                </body>
                </html>
            `;
            
            const doc = new DOMParser().parseFromString(testHtml, 'text/html');
            const result = extractMainContentWithDebug(doc);
            
            console.log('Test Extraction Results:', {
                method: result.method,
                score: result.score,
                candidates: result.candidatesCount,
                contentLength: result.content.length,
                content: result.content.substring(0, 200) + '...'
            });
            
            // Validate that key content is extracted
            const expectedContent = ['Main Article Title', 'first paragraph', 'second paragraph', 'Subheading', 'List item', 'Final paragraph'];
            const hasAllContent = expectedContent.every(text => result.content.includes(text));
            
            console.log('Content validation:', hasAllContent ? 'PASSED' : 'FAILED');
            console.log('Expected content found:', expectedContent.map(text => ({ 
                text, 
                found: result.content.includes(text) 
            })));
            
            return result;
        }

        // Make test function available globally for debugging
        window.testExtractionImprovements = testExtractionImprovements;
        
        function downloadFile(filename, text) {
            const blob = new Blob([text], { type: 'text/plain;charset=utf-8' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url; a.download = filename;
            document.body.appendChild(a); a.click();
            document.body.removeChild(a); URL.revokeObjectURL(url);
        }

        dom.downloadTxtBtn.addEventListener('click', () => {
            const textContent = state.scrapeResults.filter(Boolean).sort((a,b)=> a.index - b.index).map(r => `--- Content from ${r.url} ---\n\n${r.error ? `ERROR: ${r.error}` : r.text}`).join('\n\n');
            downloadFile('scrape_results.txt', textContent);
        });

        dom.downloadJsonlBtn.addEventListener('click', () => {
            const jsonlContent = state.scrapeResults.filter(Boolean).sort((a,b)=> a.index - b.index).map(r => JSON.stringify(r)).join('\n');
            downloadFile('scrape_results.jsonl', jsonlContent);
        });
        
        dom.downloadCsvBtn.addEventListener('click', () => {
            const header = ['url', 'title', 'author', 'published_at', 'description', 'text', 'success', 'error', 'html'];
            const esc = s => `"${(s || '').toString().replace(/"/g, '""')}"`;
            const rows = state.scrapeResults.filter(Boolean).sort((a,b)=> a.index - b.index).map(r => {
                const { url, metadata, text, success, error, html } = r;
                return [url, metadata.title, metadata.author, metadata.published_at, metadata.description, text, success, error, dom.includeHtmlToggle.checked ? html : ''].map(esc).join(',');
            });
            downloadFile('scrape_results.csv', [header.join(','), ...rows].join('\n'));
        });

        dom.copyBtn.addEventListener('click', async () => {
            try {
                await navigator.clipboard.writeText(dom.resultsCode.textContent);
                dom.copyBtn.textContent = 'Copied!';
                setTimeout(() => { dom.copyBtn.textContent = 'Copy'; }, 2000);
            } catch (err) { showError('Failed to copy text.'); }
        });
    </script>
</body>
</html>
