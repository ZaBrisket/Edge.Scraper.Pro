# EdgeScraperPro - Standalone HTML Version

A professional web scraper with sports data extraction capabilities, now running as a pure HTML + Netlify Functions application.

## ðŸš€ Quick Start

### Local Development

1. Install dependencies:
```bash
npm install
```

2. Run locally:
```bash
# Using http-server
npm run serve

# Using Netlify Dev (recommended)
npm run dev
```

3. Open http://localhost:8080 (or http://localhost:8888 with Netlify Dev)

### Deployment

This app is configured for Netlify deployment:

```bash
git push origin main
```

Netlify will automatically:
- Serve the `public/` directory as static files
- Deploy serverless functions from `netlify/functions/`
- Apply environment variables from netlify.toml

## ðŸ“ Project Structure

```
edge-scraper-pro/
â”œâ”€â”€ public/                      # Static HTML application
â”‚   â”œâ”€â”€ index.html              # Main application
â”‚   â”œâ”€â”€ batch-processor.js      # Batch processing logic
â”‚   â”œâ”€â”€ enhanced-url-validator.js # URL validation
â”‚   â”œâ”€â”€ pfr-validator.js        # Sports-specific validation
â”‚   â””â”€â”€ sports-extractor.js     # Sports content extraction
â”œâ”€â”€ netlify/
â”‚   â””â”€â”€ functions/              # Serverless functions
â”‚       â”œâ”€â”€ fetch-url.js        # Main scraping endpoint
â”‚       â””â”€â”€ health.js           # Health check
â”œâ”€â”€ src/                        # Shared libraries (for functions)
â”œâ”€â”€ netlify.toml               # Netlify configuration
â”œâ”€â”€ package.json               # Minimal dependencies
â””â”€â”€ .env                       # Local environment variables
```

## ðŸ”§ Environment Variables

Set these in Netlify Dashboard > Site settings > Environment variables:

```bash
BYPASS_AUTH=true
HTTP_DEADLINE_MS=15000
PUBLIC_API_KEY=public-2024
NODE_ENV=production
```

## ðŸŽ¯ Features

- **URL Scraping**: Fetch and extract content from any public URL
- **Sports Mode**: Enhanced extraction for sports statistics sites
- **Batch Processing**: Process multiple URLs efficiently
- **Multiple Export Formats**: JSON, CSV, Excel
- **URL Validation**: Built-in validation for common patterns
- **Rate Limiting**: Respectful scraping with configurable limits

## ðŸ› ï¸ API Endpoints

### Fetch URL
```
GET /.netlify/functions/fetch-url?url=https://example.com
Headers: X-API-Key: public-2024
```

### Health Check
```
GET /.netlify/functions/health
```

## ðŸ“ License

MIT
## NDA Reviewer â€” .docx, Context-Aware Redlines, Tracked Changes

### Env Vars (Netlify)
- `ASPOSE_WORDS_APP_SID` â€” Aspose.Words Cloud App SID
- `ASPOSE_WORDS_APP_KEY` â€” Aspose.Words Cloud App Key

> Set these in Netlify â†’ Site settings â†’ Environment variables.  
> Without them, export will return `ASPOSE_CREDS_MISSING`.

### Endpoints
- `/.netlify/functions/nda-analyze` â€” POST JSON  
  `{ kind: 'docx', fileBase64 }` or `{ kind: 'text', text }`
- `/.netlify/functions/nda-export` â€” POST JSON  
  `{ originalKind, originalFileBase64?, originalText?, normalizedText, edits }`  
  Returns `application/vnd.openxmlformats-officedocument.wordprocessingml.document`

### Security
- `.docx` parsed via `mammoth` (no external entities).  
- MIME verified with `file-type`.  
- No XML evaluation.

### Performance
- Analyze works on normalized text (fast).  
- Export delegates tracked-changes computation to Aspose Cloud.  
- Client uses base64 JSON to avoid flaky multipart on Netlify.

### Backwards Compatibility
- Text flow preserved (`kind:'text'`).  
- Existing `/nda` route kept; new UI is drop-in.
